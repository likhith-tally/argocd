{{- if eq .Values.environment "" }}
apiVersion: v1
kind: ConfigMap
metadata:
  name: opentelemetry-collector-config
  namespace: obs
data:
  otel-collector-config.yaml: |
    extensions:
      health_check:
        endpoint: "0.0.0.0:13133"
        path: "/healthz"
        response_body:
          healthy: "I'm good"
          unhealthy: "I'm bad"

    receivers:
      kubeletstats:
        collection_interval: 120s
        auth_type: 'serviceAccount'
        endpoint: "https://${env:K8S_NODE_NAME}:10250"
        collect_all_network_interfaces:
          pod: true
          node: true
        insecure_skip_verify: true
        extra_metadata_labels:
          - k8s.volume.type
        k8s_api_config:
          auth_type: serviceAccount
        metric_groups:
          - container
          - pod
          - node
          - volume

        metrics:
          container.cpu.usage:
            enabled: true
          container.memory.usage:
            enabled: true
          container.memory.working_set:
            enabled: true
          container.filesystem.usage:
            enabled: true
          container.filesystem.available:
            enabled: true
          k8s.node.cpu.usage:
            enabled: true
          k8s.node.memory.available:
            enabled: true
          k8s.node.memory.usage:
            enabled: true
          k8s.pod.cpu.usage:
            enabled: true
          k8s.pod.memory.available:
            enabled: true
          k8s.pod.memory.usage:
            enabled: true
          k8s.node.network.io:
            enabled: true
          k8s.node.network.errors:
            enabled: true
          k8s.volume.available:
            enabled: true
          k8s.volume.capacity:
            enabled: true
          container.uptime:
            enabled: true
          k8s.container.memory_limit_utilization:
            enabled: true

        resource_attributes:
          k8s.node.name:
            enabled: true
          k8s.pod.uid:
            enabled: true
          k8s.pod.name:
            enabled: true
          k8s.namespace.name:
            enabled: true
          k8s.container.name:
            enabled: true
          container.id:
            enabled: true
          k8s.volume.name:
            enabled: true
          k8s.volume.type:
            enabled: true
          k8s.persistentvolumeclaim.name:
            enabled: true
          fs.type:
            enabled: true
          partition:
            enabled: true

      hostmetrics:
        collection_interval: 120s
        scrapers:
          cpu:
            metrics:
              system.cpu.logical.count:
                enabled: true
              system.cpu.physical.count:
                enabled: true
              system.cpu.utilization:
                enabled: true
          load:
            cpu_average: true
          process:
            mute_process_all_errors: true

    processors:

      k8sattributes:
        auth_type: "serviceAccount"
        passthrough: false
        filter:
          node_from_env_var: "K8S_NODE_NAME"
        extract:
          metadata:
            - k8s.pod.name
            - k8s.pod.uid
            - k8s.deployment.name
            - k8s.namespace.name
            - k8s.node.name
            - k8s.pod.start_time
            - k8s.cluster.uid
          # Pod labels which can be fetched via K8sattributeprocessor
          labels:
            - tag_name: vm_id
              key: Name
              from: node
        # Pod association using resource attributes and connection
        pod_association:
          - sources:
              - from: resource_attribute
                name: k8s.pod.uid
              - from: resource_attribute
                name: k8s.pod.ip
              - from: connection

      resource/agent:
        attributes:
          - action: upsert
            key: service.namespace
            value: agent
      attributes/agent:
        actions:
          - key: service.namespace
            action: upsert
            value: agent
          - key: service.name
            action: upsert
            value: otel-collector
          - key: tenancy
            action: insert
            value: "{{ .Values.accountIdentity }}"
          - action: upsert
            key: vm_id
            value: ${env:VM_ID}

      resourcedetection/k8snode:
        detectors: [k8snode]
        k8snode:
          node_from_env_var: "K8S_NODE_NAME"
      
      transform/metric:
        metric_statements:
          - context: datapoint
            statements:
              - set(attributes["host.name"], resource.attributes["K8S_NODE_NAME"])
              - set(attributes["vm_id"], resource.attributes["vm_id"])

    exporters:
      prometheusremotewrite:
        endpoint: {{ .Values.observability.mimirEndpoint }}/api/v1/push
        tls:
          insecure: true
        resource_to_telemetry_conversion:
          enabled: true

    service:
      extensions: [health_check]
      telemetry:
        metrics:
          address: 0.0.0.0:8888
      pipelines:
        metrics:
          receivers: [kubeletstats, hostmetrics]
          processors: [k8sattributes, attributes/agent, resourcedetection/k8snode, transform/metric]
          exporters: [prometheusremotewrite]
---
apiVersion: v1
kind: Service
metadata:
  name: opentelemetry-collector
  namespace: obs
spec:
  ports:
  - name: otlp-grpc
    port: 4317
    protocol: TCP
    targetPort: 4317
  - name: otlp-http
    port: 4318
    protocol: TCP
    targetPort: 4318
  selector:
    app: opentelemetry-collector
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: opentelemetry-collector
  namespace: obs
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: opentelemetry-collector
rules:
# 1. Access Kubernetes events
- apiGroups: [ "" ]
  resources: [ "events" ]
  verbs: [ "get", "list", "watch" ]

# 2. Read node labels
- apiGroups: [ "" ]
  resources: [ "nodes" ]
  verbs: [ "get", "list", "watch" ]

# 3. Edit pod labels
- apiGroups: [ "" ]
  resources: [ "pods" ]
  verbs: [ "get", "list", "watch", "patch" ]

# 4. Access kubelet cadvisor
- apiGroups: [ "" ]
  resources: [ "nodes/proxy" ]
  verbs: [ "get", "list" ]

- apiGroups: [ "" ]
  resources: [ "nodes/metrics", "nodes/stats" ]
  verbs: [ "get" ]

- apiGroups: [ "" ]
  resources: [ "namespaces", "services", "resourcequotas", "replicationcontrollers" ]
  verbs: [ "list", "watch", "get" ]
# Apps API group
- apiGroups: [ "apps" ]
  resources: [ "replicasets", "daemonsets", "statefulsets", "deployments" ]
  verbs: [ "list", "watch", "get" ]
# Batch API group
- apiGroups: [ "batch" ]
  resources: [ "jobs", "cronjobs" ]
  verbs: [ "list", "watch", "get" ]
# Autoscaling API group
- apiGroups: [ "autoscaling" ]
  resources: [ "horizontalpodautoscalers" ]
  verbs: [ "list", "watch", "get" ]

- apiGroups: [ "" ]
  resources: [ "persistentvolumeclaims", "persistentvolumes" ]
  verbs: [ "get", "list", "watch" ]
---

apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: opentelemetry-collector
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: opentelemetry-collector
subjects:
- kind: ServiceAccount
  name: opentelemetry-collector
  namespace: obs
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: pod-patcher
  namespace: obs
rules:
- apiGroups: [ "" ]
  resources: [ "pods" ]
  verbs: [ "patch" ]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: pod-patcher-binding
  namespace: obs
subjects:
- kind: ServiceAccount
  name: opentelemetry-collector
  namespace: obs
roleRef:
  kind: Role
  name: pod-patcher
  apiGroup: rbac.authorization.k8s.io
---

apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: opentelemetry-collector
  namespace: obs
spec:
  selector:
    matchLabels:
      app: opentelemetry-collector
  template:
    metadata:
      labels:
        app: opentelemetry-collector
    spec:
      initContainers:
      - name: kubectl
        # [TODO] Update the image from Oracle Container Registry
        # image: ocir.ap-mumbai-1.oci.oraclecloud.com/bmbr2knaixlx/observability:kubectl-1.33.3
        image: alpine/k8s:1.33.3
        command:
        - /bin/sh
        - -c
        - |
          set -e
          MAX_RETRIES=7
          DELAY=2

          for i in $(seq 1 $MAX_RETRIES); do
            NODE_LABEL=$(kubectl get node "$NODE_NAME" -o json | jq -r '.metadata.labels["Name"]')

            if [ "$NODE_LABEL" != "null" ] && [ -n "$NODE_LABEL" ]; then
              echo "[$i/$MAX_RETRIES] Got node label: $NODE_LABEL"
              kubectl patch pod "$POD_NAME" -n "$POD_NAMESPACE" \
                -p "{\"metadata\":{\"annotations\":{\"vm-id\":\"$NODE_LABEL\"}}}"
              exit 0
            fi

            echo "[$i/$MAX_RETRIES] Node label not found, retrying in ${DELAY}s..."
            sleep $DELAY
            DELAY=$((DELAY * 2)) 
          done

          echo "Failed to get node label 'Name' after $MAX_RETRIES attempts"
          exit 1
        env:
        - name: NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
      hostPID: true
      serviceAccountName: opentelemetry-collector
      nodeSelector:
        kubernetes.io/arch: amd64
      # [TODO] Update the imagePullSecrets from Oracle Container Registry
      # imagePullSecrets:
      # - name: ocirsecret
      containers:
      - name: collector
        # [TODO] Update the image from Oracle Container Registry
        # image: ocir.ap-mumbai-1.oci.oraclecloud.com/bmbr2knaixlx/observability:otel-0.126.0-amd64
        image: otel/opentelemetry-collector-contrib:0.126.0
        args:
        - "--config=/conf/otel-collector-config.yaml"
        env:
        - name: K8S_NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        - name: K8S_POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: K8S_NAMESPACE_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: VM_ID
          valueFrom:
            fieldRef:
              fieldPath: metadata.annotations['vm-id']
        securityContext:
          runAsUser: 1000 # Run as non-root user
          runAsGroup: 1000
          capabilities:
            add: ["SYS_PTRACE"] # Add the specific capability
            drop: ["ALL"] 
        ports:
        - containerPort: 8888
        - containerPort: 4317
        - containerPort: 4318
        volumeMounts:
        - name: config
          mountPath: /conf
        resources:
          limits:
            cpu: 200m
            memory: 300Mi
          requests:
            cpu: 100m
            memory: 256Mi
      volumes:
      - name: config
        configMap:
          name: opentelemetry-collector-config
{{- end }}